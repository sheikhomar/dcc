{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca8837-2d8e-4e0e-86cb-2e39e915ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.image_dataset import load_image\n",
    "from tqdm import tqdm\n",
    "import umap\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.cluster import KMeans, Birch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f4f44-4db3-4b5f-9a8d-fef9eae4c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_extractor(model_path: str):\n",
    "    weights = \"imagenet\" if model_path is None else None\n",
    "    print(f\"Using weights: {weights}\")\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=(32, 32, 3),\n",
    "        include_top=False,\n",
    "        weights=weights,\n",
    "    )\n",
    "    base_model = tf.keras.Model(\n",
    "        base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n",
    "    )\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    if model_path is not None:\n",
    "        print(f\"Loading weights: {model_path}\")\n",
    "        model.load_weights(model_path)\n",
    "    return model\n",
    "\n",
    "def get_feature_map(model: tf.keras.Model, data_dir: str) -> Tuple[List[Path], np.ndarray]:\n",
    "    image_paths = list(sorted(Path(data_dir).glob(\"**/*.png\")))\n",
    "    n_samples = len(image_paths)\n",
    "    feature_map = np.zeros((n_samples, 256))\n",
    "    with tqdm(total=n_samples) as pbar:\n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            img = load_image(str(image_path), image_size=(32,32), num_channels=3, interpolation=\"bilinear\")\n",
    "            img = tf.expand_dims(img, axis=0) # TensorShape: [1, 32, 32, 3]\n",
    "            img_features = model(img) # TensorShape: [1, 256]\n",
    "            img_features = img_features.numpy().squeeze() # Shape: (256,)\n",
    "            feature_map[i, :] = img_features\n",
    "            pbar.update(1)\n",
    "    return image_paths, feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da85dc4-7f39-4552-b035-9c581db2133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"../experiments/original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481b66d-7654-40f6-9cb3-45e80abd865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(experiment_dir, \"checkpoints\", \"best_model\")\n",
    "# model_path = os.path.join(experiment_dir, \"checkpoints\", \"imagenet-finetuned\")\n",
    "# model_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e98ac8-06d0-416a-9c4e-12afcc854467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_feature_extractor(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa747b6-f95d-4cb3-a226-fbc2fb7462c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(experiment_dir, 'data', 'train', 'i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4235e-b7da-413d-9fb5-e89a959cedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, feature_map = get_feature_map(model, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024ce0e-7456-4ba0-9cbd-35078884c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_transformer = PCA(n_components=0.9, svd_solver=\"full\", whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c31ab-eed5-4a6a-bab6-0bc36a1af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_pca = pca_transformer.fit_transform(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e885b5-990a-4ec9-bb63-207fabedde12",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690ae0c-7ce1-40ea-9e63-f51c7b6a265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector = IsolationForest(n_estimators=1000)\n",
    "if_labels = outlier_detector.fit_predict(feature_map_pca)\n",
    "if_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dae84b-6d41-4c26-8de4-768baea6f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(if_labels == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2c36f-b3f8-4824-a5a5-467045f47e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_in_cluster = np.array(image_paths)[(if_labels == -1)]\n",
    "\n",
    "ncols = 4\n",
    "nrows = int(np.ceil(len(image_paths_in_cluster) / ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, nrows * 4))\n",
    "for ax, image_path in zip(axes.ravel(), image_paths_in_cluster):\n",
    "    img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    ax.set_title(f\"#{image_path.name}\")\n",
    "    ax.imshow(img, cmap = \"gray\", vmin=0, vmax=255)\n",
    "    #ax.axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f15490-e0cf-4617-8846-b655d15c4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = OneClassSVM()\n",
    "outlier_svm_labels = svm.fit_predict(feature_map_pca)\n",
    "outlier_svm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c06861-19cb-4e4c-80f5-9b4810c83297",
   "metadata": {},
   "outputs": [],
   "source": [
    "(outlier_svm_labels == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdada5b-7392-4f74-b953-e9490a062401",
   "metadata": {},
   "outputs": [],
   "source": [
    "(outlier_svm_labels == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c78fe-3275-4fcf-bb06-46c50d9411aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ab411-96cd-470a-9d44-6fd46d071996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = EllipticEnvelope()\n",
    "ee_labels = ee.fit_predict(feature_map_pca)\n",
    "ee_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4f353-6f03-4b1f-b099-8b3e44e2c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ee_labels == -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecc4c2-8b5a-440a-a0df-774e80e342ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_in_cluster = np.array(image_paths)[(ee_labels == -1)]\n",
    "\n",
    "ncols = 4\n",
    "nrows = int(np.ceil(len(image_paths_in_cluster) / ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, nrows * 4))\n",
    "for ax, image_path in zip(axes.ravel(), image_paths_in_cluster):\n",
    "    img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    ax.set_title(f\"#{image_path.name}\")\n",
    "    ax.imshow(img, cmap = \"gray\", vmin=0, vmax=255)\n",
    "    #ax.axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195f590-e5b6-47cb-929b-076931881931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
